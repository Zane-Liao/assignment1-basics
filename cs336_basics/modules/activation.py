import math
import torch
from torch import Tensor
from torch.nn import Module, ModuleList, Parameter
from torch.optim import Optimizer
from torch import sigmoid

__all__ = [
    "SiLU",
    "Softmax"
]


class SiLU(Module):
    def __init__():
        """"""
        raise NotImplementedError

   
class Softmax(Module):
    def __init__():
        """"""
        raise NotImplementedError
